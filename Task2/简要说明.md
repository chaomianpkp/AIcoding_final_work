# Task2 简要说明

## 任务完成情况

已完成 PyTorch 数据并行和模型并行的实现，包含三个主要文件：

### 1. `data_parallel_train.py` - 数据并行实现
- 使用 `nn.DataParallel` 实现多GPU数据并行训练
- 自动检测可用GPU数量
- 支持单GPU和多GPU两种模式对比
- 与Task1使用相同的模型架构（ImprovedCNN）

### 2. `model_parallel_train.py` - 模型并行实现  
- 手动将模型的不同部分分布在不同GPU上
- 特征提取前半部分在GPU0，后半部分和分类器在GPU1
- 在前向传播中手动管理GPU间数据传输
- 支持模型并行与单设备模式对比

### 3. `compare_parallel.py` - 性能对比脚本
- 自动运行单GPU、数据并行、模型并行三种方法
- 生成性能对比报告（准确率、训练时间、加速比）
- 提供性能分析和结论

## 快速使用

### 方法1：数据并行训练（推荐）
```bash
python data_parallel_train.py --epochs 10 --batch-size 128 --device gpu --use-parallel
```

### 方法2：模型并行训练
```bash
python model_parallel_train.py --epochs 10 --batch-size 128 --device gpu --use-model-parallel
```

### 方法3：完整对比实验
```bash
python compare_parallel.py --epochs 10 --batch-size 128
```

## 主要特点

1. **统一命令行格式**：与Task1/Task3保持一致，使用argparse
2. **完整功能**：包含并行准备、并行训练、性能对比三个步骤
3. **详细日志**：输出训练过程、准确率、时间等详细信息
4. **灵活配置**：支持epochs、batch_size、lr等参数调整

## 预期性能

- **单GPU**：准确率 ~78-82%，每个epoch约100秒
- **数据并行（2GPU）**：准确率 ~78-82%，每个epoch约55-65秒（加速比~1.5-1.8x）
- **模型并行（2GPU）**：准确率 ~78-82%，每个epoch约90-110秒（加速比~0.9-1.1x）

**注意**：实际性能取决于硬件配置（GPU型号、显存、NVLink等）

## 与作业要求的对应

✅ **并行准备**：自动检测GPU数量，显示可用设备
✅ **数据并行**：实现多GPU数据并行训练
✅ **模型并行**：实现多GPU模型并行训练  
✅ **性能对比**：对比并行化前后的训练速度和准确率

## 技术要点

1. **数据并行**：使用PyTorch的`nn.DataParallel`自动处理batch分割和梯度汇总
2. **模型并行**：手动管理模型在GPU上的分布和数据传输
3. **性能分析**：通过对比实验分析不同并行方法的优劣和适用场景

## 注意事项

- 数据并行需要至少1个GPU（多GPU效果更好）
- 模型并行需要至少2个GPU
- 如果没有多GPU，可以运行单GPU版本作为baseline
- 模型架构与Task1保持一致，确保结果可对比


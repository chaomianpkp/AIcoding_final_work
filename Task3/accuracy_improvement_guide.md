# CIFAR-10 准确率提升指南

当前准确率：~65%，目标：>75%

## 主要改进方向

### 1. 模型架构优化 ⭐⭐⭐⭐⭐ (最有效)

**当前架构**：
- Conv(3→16) → ReLU → MaxPool
- Conv(16→32) → ReLU → MaxPool
- Linear(32×8×8 → 10)

**改进建议**：
- **增加网络深度**：添加更多卷积层（3-4个卷积层）
- **增加通道数**：64、128、256等
- **使用更好的架构**：参考VGG或ResNet的小版本
- **在分类器前添加全连接层**：Linear → ReLU → Dropout → Linear

**预期提升**：+5-10%

### 2. 数据增强 ⭐⭐⭐⭐ (高性价比)

**当前**：无数据增强

**改进建议**：
- **随机水平翻转**：`RandomHorizontalFlip`
- **随机裁剪+填充**：`RandomCrop(32, padding=4)`
- **归一化**：使用CIFAR-10的均值和标准差
- **颜色抖动**：轻微的颜色变化

**预期提升**：+3-7%

### 3. 权重初始化 ⭐⭐⭐⭐ (简单但有效)

**当前**：`randn * 0.05`（随机初始化）

**改进建议**：
- **Kaiming/He初始化**：适用于ReLU激活
  - `std = sqrt(2.0 / (in_channels * kernel_size * kernel_size))`
- **Xavier/Glorot初始化**：适用于线性层
  - `std = sqrt(2.0 / (in_features + out_features))`

**预期提升**：+2-5%

### 4. 学习率调度 ⭐⭐⭐⭐ (训练策略)

**当前**：固定学习率 1e-3

**改进建议**：
- **学习率衰减**：每个epoch后乘以0.9或0.95
- **StepLR**：每N个epoch降低学习率
- **Cosine Annealing**：余弦退火
- **初始学习率调整**：可以尝试 3e-4 到 1e-3

**预期提升**：+2-4%

### 5. 正则化 ⭐⭐⭐ (防止过拟合)

**当前**：weight_decay=0.0

**改进建议**：
- **权重衰减（L2正则）**：`--weight-decay 1e-4` 或 `5e-4`
- **Dropout**：在分类器层前添加（如果有实现）
  - `dropout_rate=0.5`

**预期提升**：+1-3%

### 6. 训练策略 ⭐⭐⭐

**当前**：5个epoch

**改进建议**：
- **增加训练轮数**：10-20个epoch
- **Early Stopping**：如果验证集准确率不再提升则停止
- **模型保存**：保存最佳模型

**预期提升**：+1-3%

### 7. 优化器参数调优 ⭐⭐

**当前**：Adam(lr=1e-3)

**改进建议**：
- **调整学习率**：尝试 1e-4 到 5e-4
- **SGD with momentum**：`SGD(lr=0.1, momentum=0.9, weight_decay=5e-4)`
- **Adam参数**：`betas=(0.9, 0.999)` 保持不变

**预期提升**：+1-2%

## 推荐实施顺序（按性价比）

1. **模型架构优化** - 效果最明显，建议先做
2. **数据增强** - 实现简单，效果好
3. **权重初始化** - 改动小，有稳定提升
4. **学习率调度** - 容易实现，提升训练稳定性
5. **正则化** - 防止过拟合，提升泛化能力
6. **增加训练轮数** - 需要更多时间，但通常有提升
7. **优化器参数调优** - 精细调优，边际收益递减

## 预期最终准确率

如果实施上述所有改进，预期可以达到 **75-85%** 的准确率。

